{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to download NLTK 'punkt' resource...\n",
      "Attempting to download NLTK 'punkt_tab' resource as suggested by error...\n",
      "Successfully downloaded or found 'punkt_tab'.\n",
      "NLTK data path: ['d:/CapstoneProjectCC/notebook/nltk_data', 'd:\\\\CapstoneProjectCC\\\\notebook\\\\nltk_data']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     d:\\CapstoneProjectCC\\notebook\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     d:\\CapstoneProjectCC\\notebook\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import ast\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define and ensure NLTK data directory exists\n",
    "nltk_data_dir = os.path.join(os.getcwd(), 'nltk_data')\n",
    "if not os.path.exists(nltk_data_dir):\n",
    "    os.makedirs(nltk_data_dir)\n",
    "\n",
    "if nltk_data_dir not in nltk.data.path:\n",
    "    nltk.data.path.append(nltk_data_dir)\n",
    "\n",
    "# Download the main 'punkt' resource\n",
    "print(\"Attempting to download NLTK 'punkt' resource...\")\n",
    "nltk.download('punkt', download_dir=nltk_data_dir)\n",
    "\n",
    "print(\"Attempting to download NLTK 'punkt_tab' resource as suggested by error...\")\n",
    "try:\n",
    "    nltk.download('punkt_tab', download_dir=nltk_data_dir)\n",
    "    print(\"Successfully downloaded or found 'punkt_tab'.\")\n",
    "except ValueError as ve: # NLTK often raises ValueError for unknown resources\n",
    "    print(f\"Note: 'punkt_tab' may not be a direct downloadable item: {ve}. The main 'punkt' resource should suffice if complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Error trying to download 'punkt_tab': {e}. The main 'punkt' resource should provide necessary components.\")\n",
    "\n",
    "# Verify nltk.data.path\n",
    "print(f\"NLTK data path: {nltk.data.path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '../data/resep.csv' berhasil dimuat. Jumlah baris awal: 174\n"
     ]
    }
   ],
   "source": [
    "file_path_resep = '../data/resep.csv'  # Sesuaikan path jika perlu\n",
    "df = pd.DataFrame() # Inisialisasi DataFrame kosong\n",
    "try:\n",
    "    df = pd.read_csv(file_path_resep)\n",
    "    print(f\"File '{file_path_resep}' berhasil dimuat. Jumlah baris awal: {len(df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path_resep}' tidak ditemukan. Pastikan path sudah benar.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat file CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pratinjau 5 baris pertama data awal:\n",
      "                                               judul  \\\n",
      "0        377. Marmer Cake Simpel (Metode All In One)   \n",
      "1           1186. Mochi miniatur kelapa versi simple   \n",
      "2  Burnt Kentang Yogurt Cheese |¬†Diblender, Simpe...   \n",
      "3                         Wedang Kunyit Madu Praktis   \n",
      "4                 Siomay Dimsum 3 bahan paling mudah   \n",
      "\n",
      "                                                foto         penulis    porsi  \\\n",
      "0  https://img-global.cpcdn.com/recipes/7dce6b559...  Shanty Bambang  1 Orang   \n",
      "1  https://img-global.cpcdn.com/recipes/6c42f0549...      Naqiyyah üçí  2 Orang   \n",
      "2  https://img-global.cpcdn.com/recipes/a9e84b765...     Zahrotul An  1 Orang   \n",
      "3  https://img-global.cpcdn.com/recipes/e26be4b73...    Avita Unaiya  3 Orang   \n",
      "4  https://img-global.cpcdn.com/recipes/b5e1aea64...   Manja Sari Ta  2 Orang   \n",
      "\n",
      "                                               bahan  \\\n",
      "0  [{'grup': 'Bahan Utama', 'jumlah': '', 'bahan'...   \n",
      "1  [{'grup': 'Bahan Utama', 'jumlah': '', 'bahan'...   \n",
      "2  [{'grup': 'Bahan Utama', 'jumlah': '190 gr', '...   \n",
      "3  [{'grup': 'Bahan Utama', 'jumlah': '5 gr (1 Sa...   \n",
      "4  [{'grup': 'Bahan Utama', 'jumlah': '150 gr', '...   \n",
      "\n",
      "                                             langkah     durasi  \\\n",
      "0  ['Buat pasta campur semua bahan a, aduk rata s...   60 Menit   \n",
      "1  ['Sangrai kelapa parut sampai kecoklatan, sisi...  120 Menit   \n",
      "2  ['Masukkan semua bahan ke dalam blender kentan...   45 Menit   \n",
      "3  ['Tuang bubuk kunyit dan air panas di satu wad...   20 Menit   \n",
      "4  ['Masukkan semua bahan kedalam chopper', 'Halu...   60 Menit   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://cookpad.com/id/resep/24616996-377-marm...   \n",
      "1  https://cookpad.com/id/resep/24777487-1186-moc...   \n",
      "2  https://cookpad.com/id/resep/24782857-burnt-ke...   \n",
      "3  https://cookpad.com/id/resep/24782608-wedang-k...   \n",
      "4  https://cookpad.com/id/resep/24778405-siomay-d...   \n",
      "\n",
      "                               tag  \n",
      "0       ['adonan', 'keju', 'cake']  \n",
      "1      ['kelapa', 'mochi', 'rose']  \n",
      "2  ['yogurt', 'dingin', 'kentang']  \n",
      "3    ['kunyit', 'gelas', 'wedang']  \n",
      "4  ['dimsum', 'siomay', 'kukusan']  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPratinjau 5 baris pertama data awal:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setelah filter judul: 174 baris tersisa (dari 174).\n"
     ]
    }
   ],
   "source": [
    "if 'judul' in df.columns:\n",
    "    initial_rows = len(df)\n",
    "    df.dropna(subset=['judul'], inplace=True) # Hapus baris dengan judul NaN\n",
    "    df = df[df['judul'].apply(lambda x: isinstance(x, str) and x.strip().lower() not in ['', 'judul tidak ditemukan'])]\n",
    "    print(f\"\\nSetelah filter judul: {len(df)} baris tersisa (dari {initial_rows}).\")\n",
    "else:\n",
    "    print(\"Peringatan: Kolom 'judul' tidak ditemukan. Tidak dapat melakukan filter berdasarkan judul.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.empty:\n",
    "    print(\"DataFrame menjadi kosong setelah filter judul. Tidak dapat melanjutkan.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ingredients_from_string(bahan_str):\n",
    "    \"\"\"Mengekstrak daftar nama bahan dari string yang berisi list of dict.\"\"\"\n",
    "    if not isinstance(bahan_str, str):\n",
    "        return \"\" # Kembalikan string kosong jika input bukan string\n",
    "    try:\n",
    "        # Sanitasi untuk kasus umum seperti 'null' JSON ke 'None' Python\n",
    "        bahan_str_sanitized = bahan_str.replace('null', 'None').replace('true', 'True').replace('false', 'False')\n",
    "        bahan_list_data = ast.literal_eval(bahan_str_sanitized)\n",
    "        \n",
    "        extracted_names = []\n",
    "        if isinstance(bahan_list_data, list):\n",
    "            for item_dict in bahan_list_data:\n",
    "                if isinstance(item_dict, dict) and 'bahan' in item_dict and isinstance(item_dict['bahan'], str):\n",
    "                    if item_dict['bahan'].strip(): # Pastikan nama bahan tidak kosong\n",
    "                        extracted_names.append(item_dict['bahan'].strip())\n",
    "        return ' '.join(extracted_names) # Gabungkan semua nama bahan menjadi satu string\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return \"\" # Jika parsing gagal atau format tidak sesuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai ekstraksi teks bahan dari kolom 'bahan'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ekstraksi bahan_text: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 174/174 [00:00<00:00, 2896.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setelah ekstraksi dan filter bahan_text kosong: 172 baris tersisa (dari 174).\n",
      "\n",
      "Contoh 'bahan_text' setelah ekstraksi:\n",
      "                                               judul  \\\n",
      "0        377. Marmer Cake Simpel (Metode All In One)   \n",
      "1           1186. Mochi miniatur kelapa versi simple   \n",
      "2  Burnt Kentang Yogurt Cheese |¬†Diblender, Simpe...   \n",
      "3                         Wedang Kunyit Madu Praktis   \n",
      "4                 Siomay Dimsum 3 bahan paling mudah   \n",
      "\n",
      "                                          bahan_text  \n",
      "0  pasta Coklat Coklat Bubuk Air Panas Bahan Bias...  \n",
      "1  Daging Kelapa Santan Rose Brand Tapioka Rose B...  \n",
      "2  Kentang Kukus Yogurt Plain Telur Mentega Cair ...  \n",
      "3         Bubuk Kunyit Desaku Air Panas Madu Es Batu  \n",
      "4  Dada Ayam Segar Wortel Es Batu Bawang Putih Ta...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 'bahan' in df.columns:\n",
    "    print(\"\\nMemulai ekstraksi teks bahan dari kolom 'bahan'...\")\n",
    "    tqdm.pandas(desc=\"Ekstraksi bahan_text\")\n",
    "    df['bahan_text'] = df['bahan'].progress_apply(extract_ingredients_from_string)\n",
    "    \n",
    "    # Filter baris yang tidak memiliki bahan_text setelah ekstraksi\n",
    "    initial_rows = len(df)\n",
    "    df = df[df['bahan_text'].str.strip() != '']\n",
    "    print(f\"Setelah ekstraksi dan filter bahan_text kosong: {len(df)} baris tersisa (dari {initial_rows}).\")\n",
    "    \n",
    "    if not df.empty:\n",
    "        print(\"\\nContoh 'bahan_text' setelah ekstraksi:\")\n",
    "        print(df[['judul', 'bahan_text']].head())\n",
    "    else:\n",
    "        print(\"DataFrame menjadi kosong setelah ekstraksi bahan_text. Tidak dapat melanjutkan.\")\n",
    "        exit()\n",
    "else:\n",
    "    print(\"Peringatan: Kolom 'bahan' tidak ditemukan. Tidak dapat mengekstrak 'bahan_text'.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inisialisasi Stemmer Sastrawi...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nInisialisasi Stemmer Sastrawi...\")\n",
    "stemmer = StemmerFactory().create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamus slang dari '../script/slang.txt' berhasil dimuat (1953 entri).\n"
     ]
    }
   ],
   "source": [
    "slang_path = '../script/slang.txt'  # Sesuaikan path jika perlu\n",
    "slang_dict = {}\n",
    "try:\n",
    "    with open(slang_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line or ' : ' not in line:\n",
    "                continue\n",
    "            slang, formal = line.split(' : ', 1) # Pemisah ' : '\n",
    "            slang_dict[slang.strip()] = formal.strip()\n",
    "    print(f\"Kamus slang dari '{slang_path}' berhasil dimuat ({len(slang_dict)} entri).\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Peringatan: File kamus slang '{slang_path}' tidak ditemukan. Normalisasi slang mungkin tidak dilakukan.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat kamus slang: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daftar stopword dari '../script/stopwords-tag.txt' berhasil dimuat (994 entri).\n"
     ]
    }
   ],
   "source": [
    "stopword_path = '../script/stopwords-tag.txt'  # Sesuaikan path jika perlu\n",
    "custom_stopwords = set()\n",
    "try:\n",
    "    with open(stopword_path, 'r', encoding='utf-8') as f:\n",
    "        custom_stopwords = set(line.strip().lower() for line in f if line.strip())\n",
    "    print(f\"Daftar stopword dari '{stopword_path}' berhasil dimuat ({len(custom_stopwords)} entri).\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Peringatan: File stopword '{stopword_path}' tidak ditemukan. Penghapusan stopword standar mungkin tidak dilakukan.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saat memuat stopwords: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_bahan(text):\n",
    "    \"\"\"Membersihkan dan memproses teks bahan: lowercase, hapus angka & simbol, normalisasi slang, hapus stopwords, stemming.\"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()  # Lowercasing\n",
    "    text = re.sub(r'\\d+', '', text)  # Hapus angka\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Hapus simbol, sisakan huruf dan spasi\n",
    "    text = text.strip() # Hapus spasi berlebih di awal/akhir setelah regex\n",
    "\n",
    "    tokens = word_tokenize(text) # Tokenisasi\n",
    "    \n",
    "    # Normalisasi slang\n",
    "    normalized_tokens = [slang_dict.get(token, token) for token in tokens]\n",
    "    \n",
    "    # Hapus stopwords dan token pendek\n",
    "    filtered_tokens = [token for token in normalized_tokens if token not in custom_stopwords and len(token) > 1]\n",
    "    \n",
    "    # Stemming\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "    \n",
    "    return ' '.join(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai preprocessing teks bahan untuk 'clean_bahan'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing clean_bahan: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 172/172 [00:33<00:00,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setelah preprocessing dan filter clean_bahan kosong: 172 baris tersisa (dari 172).\n",
      "\n",
      "Contoh 'clean_bahan' setelah preprocessing:\n",
      "                                               judul  \\\n",
      "0        377. Marmer Cake Simpel (Metode All In One)   \n",
      "1           1186. Mochi miniatur kelapa versi simple   \n",
      "2  Burnt Kentang Yogurt Cheese |¬†Diblender, Simpe...   \n",
      "3                         Wedang Kunyit Madu Praktis   \n",
      "4                 Siomay Dimsum 3 bahan paling mudah   \n",
      "\n",
      "                                         clean_bahan  \n",
      "0  pasta coklat coklat bubuk margarine gula telur...  \n",
      "1  daging kelapa tapioka gambar tani maizena gula...  \n",
      "2  kentang kukus yogurt plain telur mentega cair ...  \n",
      "3                          bubuk kunyit madu es batu  \n",
      "4  dada ayam wortel es batu bawang putih tapioka ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if 'bahan_text' in df.columns:\n",
    "    print(\"\\nMemulai preprocessing teks bahan untuk 'clean_bahan'...\")\n",
    "    tqdm.pandas(desc=\"Preprocessing clean_bahan\")\n",
    "    df['clean_bahan'] = df['bahan_text'].progress_apply(preprocess_text_bahan)\n",
    "    initial_rows = len(df)\n",
    "    df.dropna(subset=['clean_bahan'], inplace=True) \n",
    "    df = df[df['clean_bahan'].str.strip() != ''] \n",
    "    print(f\"Setelah preprocessing dan filter clean_bahan kosong: {len(df)} baris tersisa (dari {initial_rows}).\")\n",
    "    if not df.empty:\n",
    "        print(\"\\nContoh 'clean_bahan' setelah preprocessing:\")\n",
    "        print(df[['judul', 'clean_bahan']].head())\n",
    "    else:\n",
    "        print(\"DataFrame menjadi kosong setelah preprocessing clean_bahan. Tidak dapat melanjutkan ke TF-IDF.\")\n",
    "        exit()\n",
    "else:\n",
    "    print(\"Kolom 'bahan_text' tidak ditemukan, tidak dapat membuat 'clean_bahan'.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame di-reset indexnya, jumlah baris saat ini untuk TF-IDF: 172\n"
     ]
    }
   ],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "print(f\"\\nDataFrame di-reset indexnya, jumlah baris saat ini untuk TF-IDF: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai vektorisasi TF-IDF pada kolom 'clean_bahan'...\n",
      "Matriks TF-IDF berhasil dibuat dengan dimensi: (172, 348)\n",
      "DataFrame TF-IDF berhasil dibuat.\n",
      "\n",
      "Kolom 'judul' berhasil digabungkan dengan DataFrame TF-IDF.\n",
      "Pratinjau data gabungan:\n",
      "                                               judul  agaragar  almond  \\\n",
      "0        377. Marmer Cake Simpel (Metode All In One)       0.0     0.0   \n",
      "1           1186. Mochi miniatur kelapa versi simple       0.0     0.0   \n",
      "2  Burnt Kentang Yogurt Cheese |¬†Diblender, Simpe...       0.0     0.0   \n",
      "3                         Wedang Kunyit Madu Praktis       0.0     0.0   \n",
      "4                 Siomay Dimsum 3 bahan paling mudah       0.0     0.0   \n",
      "\n",
      "   alpukat  ambon  anak  asa  asam  asin  ayak  ...  vanila  vanili  vanilla  \\\n",
      "0      0.0    0.0   0.0  0.0   0.0   0.0   0.0  ...     0.0     0.0      0.0   \n",
      "1      0.0    0.0   0.0  0.0   0.0   0.0   0.0  ...     0.0     0.0      0.0   \n",
      "2      0.0    0.0   0.0  0.0   0.0   0.0   0.0  ...     0.0     0.0      0.0   \n",
      "3      0.0    0.0   0.0  0.0   0.0   0.0   0.0  ...     0.0     0.0      0.0   \n",
      "4      0.0    0.0   0.0  0.0   0.0   0.0   0.0  ...     0.0     0.0      0.0   \n",
      "\n",
      "   vanilli  velvet  warna     wijen    wortel    yogurt  yum  \n",
      "0      0.0     0.0    0.0  0.000000  0.000000  0.000000  0.0  \n",
      "1      0.0     0.0    0.0  0.000000  0.000000  0.000000  0.0  \n",
      "2      0.0     0.0    0.0  0.000000  0.000000  0.394171  0.0  \n",
      "3      0.0     0.0    0.0  0.000000  0.000000  0.000000  0.0  \n",
      "4      0.0     0.0    0.0  0.245698  0.436514  0.000000  0.0  \n",
      "\n",
      "[5 rows x 349 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data TF-IDF (termasuk judul) berhasil disimpan ke '../data/resep_tfidf_features.csv'\n",
      "\n",
      "Skrip preprocessing selesai.\n"
     ]
    }
   ],
   "source": [
    "if not df.empty and 'clean_bahan' in df.columns:\n",
    "    print(\"\\nMemulai vektorisasi TF-IDF pada kolom 'clean_bahan'...\")\n",
    "    vectorizer = TfidfVectorizer() # Inisialisasi default\n",
    "    \n",
    "    try:\n",
    "        tfidf_matrix = vectorizer.fit_transform(df['clean_bahan'])\n",
    "        print(f\"Matriks TF-IDF berhasil dibuat dengan dimensi: {tfidf_matrix.shape}\")\n",
    "\n",
    "        # Membuat DataFrame dari matriks TF-IDF\n",
    "        tfidf_df = pd.DataFrame(\n",
    "            tfidf_matrix.toarray(),\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "        print(\"DataFrame TF-IDF berhasil dibuat.\")\n",
    "\n",
    "        # --- 9. Menggabungkan Judul dengan Fitur TF-IDF ---\n",
    "        # Pastikan df['judul'] memiliki indeks yang sesuai dengan tfidf_df (sudah di-handle dengan reset_index sebelumnya)\n",
    "        output_df_with_tfidf = pd.concat([df[['judul']], tfidf_df], axis=1)\n",
    "        print(\"\\nKolom 'judul' berhasil digabungkan dengan DataFrame TF-IDF.\")\n",
    "        print(\"Pratinjau data gabungan:\")\n",
    "        print(output_df_with_tfidf.head())\n",
    "\n",
    "        # --- 10. Menyimpan Hasil TF-IDF ke CSV ---\n",
    "        output_csv_filename_tfidf = '../data/resep_tfidf_features.csv' # Nama file output baru\n",
    "        try:\n",
    "            output_df_with_tfidf.to_csv(output_csv_filename_tfidf, index=False, encoding='utf-8')\n",
    "            print(f\"\\nData TF-IDF (termasuk judul) berhasil disimpan ke '{output_csv_filename_tfidf}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saat menyimpan CSV TF-IDF: {e}\")\n",
    "            \n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError selama TF-IDF: {ve}\")\n",
    "        print(\"Ini bisa terjadi jika 'clean_bahan' berisi semua entri kosong setelah preprocessing.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error saat proses TF-IDF: {e}\")\n",
    "else:\n",
    "    print(\"Tidak ada data 'clean_bahan' yang valid untuk diproses TF-IDF.\")\n",
    "\n",
    "print(\"\\nSkrip preprocessing selesai.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-global",
   "language": "python",
   "name": "python-global"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
