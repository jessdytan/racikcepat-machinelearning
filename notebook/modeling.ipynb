{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/resep_tfidf_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan judul resep dan fitur bahan\n",
    "recipe_titles = df.iloc[:, 0].tolist()\n",
    "X_features_df = df.iloc[:, 1:]\n",
    "ingredient_list = X_features_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversi data resep menjadi TENSOR TensorFlow\n",
    "recipe_matrix_binary = tf.constant(X_features_df.values > 0, dtype=tf.bool)\n",
    "recipe_matrix_tfidf = tf.constant(X_features_df.values, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data berhasil dimuat ke dalam TensorFlow Tensor.\n",
      "Jumlah resep: 172, Jumlah bahan unik: 348\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data berhasil dimuat ke dalam TensorFlow Tensor.\")\n",
    "print(f\"Jumlah resep: {recipe_matrix_binary.shape[0]}, Jumlah bahan unik: {recipe_matrix_binary.shape[1]}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecipeClassifier(tf.keras.Model):\n",
    "    def __init__(self, num_recipes):\n",
    "        super(RecipeClassifier, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.output_layer = tf.keras.layers.Dense(num_recipes, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = RecipeClassifier(len(recipe_titles))\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = recipe_matrix_binary.numpy().astype(np.float32)\n",
    "y_train = np.arange(len(recipe_titles))  # Each recipe is its own class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 5.1521\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0640 - loss: 5.0356\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2056 - loss: 4.9284\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3997 - loss: 4.8185\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5060 - loss: 4.6938\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5381 - loss: 4.5341\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6485 - loss: 4.3328\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6335 - loss: 4.1715\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7215 - loss: 3.8028\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7165 - loss: 3.5911\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7960 - loss: 3.2013\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8231 - loss: 2.9911\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8550 - loss: 2.4900\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9115 - loss: 2.1971\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9367 - loss: 1.9770\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9628 - loss: 1.5474\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9865 - loss: 1.3618\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9853 - loss: 1.0705\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9856 - loss: 0.8718\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9926 - loss: 0.6734\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.5816\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.4541\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.3611\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.3179\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.2670\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.2381\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1918\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1769\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1523\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1273\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.1174\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.1063\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0931\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0848\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0817\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0631\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0617\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0566\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0464\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0493\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0468\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0447\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0377\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0355\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0312 \n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0326\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0365\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0290\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0291\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x297eb1b8940>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recipe_final(ingredients_input, titles, ingredients, matrix_binary, verbose=True):\n",
    "    \"\"\"\n",
    "    Memproses input bahan menggunakan logika filtering dan skoring murni dengan TensorFlow.\n",
    "    `verbose=False` untuk mematikan print saat evaluasi.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(f\"\\n--- MENCARI RESEP UNTUK: {ingredients_input} ---\")\n",
    "\n",
    "    tokenized_input = []\n",
    "    for item in ingredients_input:\n",
    "        words = re.split(r'\\s+', str(item).lower())\n",
    "        tokenized_input.extend(words)\n",
    "    \n",
    "    input_mask_np = np.isin(ingredients, tokenized_input)\n",
    "    \n",
    "    if not np.any(input_mask_np):\n",
    "        return \"NO_MATCH_INGREDIENTS\" # Return kode untuk evaluasi\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Bahan dikenali: {[ing for ing in tokenized_input if ing in ingredients]}\")\n",
    "    \n",
    "    input_mask = tf.constant(input_mask_np, dtype=tf.bool)\n",
    "    \n",
    "    missing_ingredients_mask = tf.logical_and(tf.logical_not(matrix_binary), input_mask)\n",
    "    missing_count_per_recipe = tf.reduce_sum(tf.cast(missing_ingredients_mask, tf.int32), axis=1)\n",
    "    passing_recipes_mask = tf.equal(missing_count_per_recipe, 0)\n",
    "    \n",
    "    if not tf.reduce_any(passing_recipes_mask):\n",
    "        return \"NO_MATCH_RECIPE\" # Return kode untuk evaluasi\n",
    "\n",
    "    intersection = tf.reduce_sum(tf.cast(tf.logical_and(matrix_binary, input_mask), tf.float32), axis=1)\n",
    "    total_ingredients_in_recipe = tf.reduce_sum(tf.cast(matrix_binary, tf.float32), axis=1)\n",
    "    efficiency_score = intersection / (total_ingredients_in_recipe + 1e-6)\n",
    "    \n",
    "    final_scores = tf.where(passing_recipes_mask, efficiency_score, 0.0)\n",
    "    \n",
    "    best_recipe_index = tf.argmax(final_scores)\n",
    "    best_score = final_scores[best_recipe_index]\n",
    "    \n",
    "    if best_score <= 0:\n",
    "        return \"NO_MATCH_SCORE\" # Return kode untuk evaluasi\n",
    "        \n",
    "    matched_recipe_name = titles[best_recipe_index]\n",
    "    \n",
    "    # Untuk pemanggilan normal, kembalikan string yang informatif\n",
    "    if verbose:\n",
    "        return f\"Resep yang paling sesuai adalah: **{matched_recipe_name}** (Skor Kecocokan: {best_score:.2f})\"\n",
    "    # Untuk evaluasi, kembalikan hanya judulnya\n",
    "    else:\n",
    "        return matched_recipe_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_suite(data_df, titles, ingredients, model):\n",
    "    print(\"\\n--- MEMULAI EVALUASI KINERJA MODEL (Tanpa find_recipe_final) ---\")\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(len(titles)):\n",
    "        true_title = titles[i]\n",
    "        recipe_ingredients_series = data_df.iloc[i, 1:]\n",
    "        important_ingredients = recipe_ingredients_series[recipe_ingredients_series > 0].sort_values(ascending=False)\n",
    "        num_to_keep = max(2, int(len(important_ingredients) * 0.7))\n",
    "        test_ingredients = important_ingredients.head(num_to_keep).index.tolist()\n",
    "\n",
    "        # Tokenisasi dan ubah ke input vector\n",
    "        tokenized_input = []\n",
    "        for item in test_ingredients:\n",
    "            tokenized_input.extend(re.split(r'\\s+', str(item).lower()))\n",
    "\n",
    "        input_vector = np.isin(ingredients, tokenized_input).astype(np.float32)\n",
    "        \n",
    "        # Jika tidak ada bahan dikenali, lewati\n",
    "        if np.sum(input_vector) == 0:\n",
    "            continue\n",
    "\n",
    "        input_tensor = tf.convert_to_tensor([input_vector], dtype=tf.float32)\n",
    "        prediction = model(input_tensor).numpy().squeeze()\n",
    "        predicted_index = np.argmax(prediction)\n",
    "        predicted_title = titles[predicted_index]\n",
    "\n",
    "        y_true.append(true_title)\n",
    "        y_pred.append(predicted_title)\n",
    "        \n",
    "        if (i + 1) % 40 == 0 or (i + 1) == len(titles):\n",
    "            print(f\"Evaluasi selesai untuk {i + 1}/{len(titles)} resep...\")\n",
    "\n",
    "    print(\"\\n--- HASIL METRIK EVALUASI ---\")\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Akurasi Keseluruhan: {accuracy:.2%}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, zero_division=0))\n",
    "\n",
    "    unique_labels = sorted(list(set(y_true + y_pred)))\n",
    "    if len(unique_labels) < 30:\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=unique_labels)\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=unique_labels, yticklabels=unique_labels, cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('Label Sebenarnya (True)')\n",
    "        plt.xlabel('Label Prediksi')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aset model berhasil disimpan ke: ../model/recipe_model.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_model_assets(filepath, titles, ingredients, model):\n",
    "    model_assets = {\n",
    "        \"recipe_titles\": titles,\n",
    "        \"ingredient_list\": ingredients,\n",
    "        \"model_weights\": model.get_weights()\n",
    "    }\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model_assets, f)\n",
    "    print(f\"\\nAset model berhasil disimpan ke: {filepath}\")\n",
    "\n",
    "save_model_assets(\"../model/recipe_model.pkl\", recipe_titles, ingredient_list, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resep di dalam database: 172\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open(\"../model/recipe_model.pkl\", 'rb') as f:\n",
    "    loaded_assets = pickle.load(f)\n",
    "\n",
    "loaded_model = RecipeClassifier(len(loaded_assets[\"recipe_titles\"]))\n",
    "_ = loaded_model(tf.zeros((1, len(loaded_assets[\"ingredient_list\"]))))\n",
    "loaded_model.set_weights(loaded_assets[\"model_weights\"])\n",
    "recipe_titles = loaded_assets[\"recipe_titles\"]\n",
    "ingredient_list = loaded_assets[\"ingredient_list\"]\n",
    "\n",
    "print(f\"Total resep di dalam database: {len(recipe_titles)}\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recipes(ingredients_input, num_recommendations=5, min_score_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Menemukan semua resep yang mengandung bahan input, diurutkan\n",
    "    berdasarkan kecocokan tertinggi (Jaccard Similarity).\n",
    "    \"\"\"\n",
    "    print(f\"\\n🍳 Mencari resep untuk: {ingredients_input}...\")\n",
    "\n",
    "    # 1. Tokenisasi dan persiapan input\n",
    "    tokenized_input = []\n",
    "    for item in ingredients_input:\n",
    "        words = re.split(r'\\s+', str(item).lower())\n",
    "        tokenized_input.extend(words)\n",
    "    \n",
    "    input_mask_np = np.isin(ingredient_list, tokenized_input)\n",
    "    \n",
    "    recognized_ingredients = [ing for ing in tokenized_input if ing in ingredient_list]\n",
    "    if not recognized_ingredients:\n",
    "        return \"Tidak ada bahan yang dikenali dalam sistem kami.\"\n",
    "    \n",
    "    input_mask = tf.constant(input_mask_np, dtype=tf.bool)\n",
    "    \n",
    "    # 2. Skoring Cerdas untuk SEMUA resep (tanpa filter awal)\n",
    "    intersection = tf.reduce_sum(tf.cast(tf.logical_and(recipe_matrix_binary, input_mask), tf.float32), axis=1)\n",
    "    union = tf.reduce_sum(tf.cast(tf.logical_or(recipe_matrix_binary, input_mask), tf.float32), axis=1)\n",
    "    \n",
    "    # Skor Jaccard dihitung untuk semua resep\n",
    "    final_scores = intersection / (union + 1e-6) # Ditambah epsilon untuk menghindari pembagian dengan nol\n",
    "\n",
    "    # 3. Cek apakah ada kecocokan sempurna (skor >= 0.999)\n",
    "    perfect_match_indices = tf.where(final_scores >= 0.999).numpy().flatten()\n",
    "    \n",
    "    if len(perfect_match_indices) > 0:\n",
    "        response = \"**Resep Relevan Ditemukan!**\\nBahan Anda cocok sempurna dengan resep berikut:\\n\"\n",
    "        for idx in perfect_match_indices:\n",
    "            response += f\"- **{recipe_titles[idx]}**\\n\"\n",
    "        return response\n",
    "    \n",
    "    # 4. Jika tidak ada yang sempurna, cari beberapa rekomendasi terbaik\n",
    "    else:\n",
    "        # Ambil top N rekomendasi dari semua skor\n",
    "        top_k_scores, top_k_indices = tf.nn.top_k(final_scores, k=num_recommendations)\n",
    "        \n",
    "        recommendations = []\n",
    "        for i in range(len(top_k_scores.numpy())):\n",
    "            score = top_k_scores.numpy()[i]\n",
    "            index = top_k_indices.numpy()[i]\n",
    "            \n",
    "            # Hanya tampilkan jika skor di atas ambang batas minimal\n",
    "            if score >= min_score_threshold:\n",
    "                recommendations.append((recipe_titles[index], score))\n",
    "        \n",
    "        if recommendations:\n",
    "            response = \"**Berikut Rekomendasi Resep yang Mengandung Bahan Anda:**\\n(Diurutkan dari yang paling cocok)\\n\"\n",
    "            for i, (title, score) in enumerate(recommendations):\n",
    "                response += f\"{i+1}. **{title}** (Skor Kecocokan: {score:.2f})\\n\"\n",
    "            return response\n",
    "        else:\n",
    "            return f\"Tidak ada resep yang cocok (Skor tertinggi di bawah ambang batas {min_score_threshold}).\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🍳 Mencari resep untuk: ['mie instan goreng', 'telur', 'kaldu jamur']...\n",
      "**Resep Relevan Ditemukan!**\n",
      "Bahan Anda cocok sempurna dengan resep berikut:\n",
      "- **Omelet Mie (instant goreng)**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bahan = ['mie instan goreng', 'telur', 'kaldu jamur']\n",
    "hasil = find_recipes(bahan)\n",
    "print(hasil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🍳 Mencari resep untuk: ['mie', 'ayam']...\n",
      "**Berikut Rekomendasi Resep yang Mengandung Bahan Anda:**\n",
      "(Diurutkan dari yang paling cocok)\n",
      "1. **Bubur Ayam Sat Set** (Skor Kecocokan: 0.33)\n",
      "2. **Pizza mie instan** (Skor Kecocokan: 0.20)\n",
      "3. **Mie goreng instan** (Skor Kecocokan: 0.20)\n",
      "4. **Mie Kriuk (Mie Goreng Instan)** (Skor Kecocokan: 0.20)\n",
      "5. **Omelet Mie (instant goreng)** (Skor Kecocokan: 0.17)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bahan = ['mie', 'ayam']\n",
    "hasil = find_recipes(bahan)\n",
    "print(hasil)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-global",
   "language": "python",
   "name": "python-global"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
